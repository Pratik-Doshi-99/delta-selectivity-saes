{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37eb08e2-27f9-4f54-bbfa-4089da8c6f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9301c253-b925-4a05-932f-b6715e0c84d7",
   "metadata": {},
   "source": [
    "## Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "661aa506-c89b-47c8-9518-b94c9df30b34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "<class 'list'>\n",
      "tensor([[ 4.1510, -3.1324, -3.7719,  ...,  4.2293,  0.8748,  4.9505],\n",
      "        [ 2.2299, -5.2020, -1.1876,  ...,  4.1518,  3.2206,  2.9460],\n",
      "        [ 2.2062, -5.0050, -1.3131,  ...,  4.0102,  4.9438,  3.1352],\n",
      "        ...,\n",
      "        [ 4.2059, -3.8782, -2.3155,  ...,  2.8275,  4.2289,  3.1904],\n",
      "        [ 3.5817, -3.9885, -1.8343,  ...,  2.8444,  2.8576,  3.9636],\n",
      "        [ 2.0455, -5.9668, -3.0935,  ...,  2.5516,  3.8778,  3.7874]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 1.6959, -4.5681, -1.4350,  ...,  0.3939,  4.5218,  2.3154],\n",
      "        [ 1.7796, -4.1511, -2.0905,  ...,  0.7387,  3.5026,  2.5950],\n",
      "        [ 2.3684, -5.2151, -1.6547,  ...,  3.5315,  2.6439,  3.5872],\n",
      "        ...,\n",
      "        [ 3.2048, -5.0878, -2.7448,  ...,  3.5497,  3.7747,  4.5994],\n",
      "        [ 2.8391, -4.7629, -0.9800,  ...,  3.5414,  3.2388,  2.7959],\n",
      "        [ 1.7317, -5.0235, -1.9212,  ...,  1.2924,  4.7483,  2.4162]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 3.2449, -4.5166, -2.0695,  ...,  4.0228,  3.9382,  3.4261],\n",
      "        [ 3.3835, -4.7500, -2.6298,  ...,  2.7128,  3.9604,  3.4382],\n",
      "        [ 3.8624, -3.7187, -2.6085,  ...,  3.0612,  3.5445,  3.2497],\n",
      "        ...,\n",
      "        [ 3.5569, -4.0321, -2.6101,  ...,  4.2732,  2.8302,  3.0212],\n",
      "        [ 2.2440, -3.3627, -3.1593,  ...,  2.9497,  0.6712,  4.5086],\n",
      "        [ 1.3868, -3.6684, -1.9024,  ...,  0.4100,  5.2489,  2.7826]],\n",
      "       device='cuda:0')\n",
      "_________________________\n",
      "1024\n",
      "<class 'list'>\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16)\n",
      "_________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 9704.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#model = 'activations_pythia_410m/data_subset/model-activations/EleutherAI_pythia-410m_11L_9.pt'\n",
    "#sae = 'activations_pythia_410m/data_subset/sae-activations/EleutherAI_sae-pythia-410m-65k_11L_9.pt'\n",
    "model = 'activations_pythia_160m/nat_lang/model-activations/EleutherAI_pythia-160m_11L_27.pt'\n",
    "sae = 'activations_pythia_160m/nat_lang/sae-activations/EleutherAI_sae-pythia-160m-32k_11L_27.pt'\n",
    "\n",
    "\n",
    "checkpoint_model = torch.load(model, map_location=torch.device('cuda:0'), weights_only=False)\n",
    "print(len(checkpoint_model))\n",
    "print(type(checkpoint_model))\n",
    "print(checkpoint_model[3])\n",
    "print(checkpoint_model[4])\n",
    "print(checkpoint_model[5])\n",
    "\n",
    "print('_'*25)\n",
    "checkpoint_sae = torch.load(sae, map_location=torch.device('cuda:0'), weights_only=False)\n",
    "checkpoint_sae = [c.to_dense() if c is not None else None for c in checkpoint_sae]\n",
    "print(len(checkpoint_sae))\n",
    "print(type(checkpoint_sae))\n",
    "print(checkpoint_sae[3])\n",
    "print(checkpoint_sae[4])\n",
    "print(checkpoint_sae[5])\n",
    "\n",
    "print('_'*25)\n",
    "# Tallies?\n",
    "assert len(checkpoint_sae) == len(checkpoint_model), \"Lengths dont match\"\n",
    "for i in tqdm.tqdm(range(len(checkpoint_sae))):\n",
    "    if checkpoint_sae[i] is not None:\n",
    "        assert checkpoint_sae[i].shape[0] == checkpoint_sae[i].shape[0], f\"Positions dont match for index {i}\"\n",
    "        non_zero = (checkpoint_sae[i] != 0).sum(dim = -1)\n",
    "        assert non_zero.max() == 32, f\"More than 32 non zeros: {non_zero.max()}, at index {i}\"\n",
    "        # sometimes there can be instance where there are less than 32 activations that are non zero, but there can never be more than 32\n",
    "        #assert non_zero.min() == 32, f\"Less than 32 non zeros: {non_zero.min()}, at index {i}\"\n",
    "        if non_zero.min() < 32:\n",
    "            f\"Less than 32 non zeros: {non_zero.min()}, at index {i}\"\n",
    "            \n",
    "\n",
    "print('_'*25)\n",
    "assert sum([1 if c is None else 0 for c in checkpoint_sae]) == sum([1 if c is None else 0 for c in checkpoint_model]), \"Unequal Number of Nones\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "221bb9be-d75d-4d20-b3d8-d99287f31f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([54, 65536])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_sae[334].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55d8acd9-4180-44a6-b25a-c03f9dced63d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([30, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
       "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
       "        32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(checkpoint_sae[334] != 0).sum(dim = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bce6b5-bb40-4607-bf1f-981160a8feb9",
   "metadata": {},
   "source": [
    "## Whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a34b3497-fc86-4621-b3b4-111348fd5bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_pattern = 'activations_pythia_160m/nat_lang/model-activations/*_11L_*.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db37dcf4-5926-42e7-bee5-1958e684ad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob.glob(dir_pattern)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f0a0fe-e2ca-4129-bf42-72f3ee389c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_activations = []\n",
    "for file in tqdm.tqdm(all_files):\n",
    "    checkpoint_model = torch.load(model, map_location=torch.device(device), weights_only=False)\n",
    "    for i in range(len(checkpoint_model)):\n",
    "        if checkpoint_model[i].is_sparse:\n",
    "            checkpoint_model[i] = checkpoint_model[i].to_dense()\n",
    "    all_activations += checkpoint_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
