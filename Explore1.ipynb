{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f01d92e6-c4ed-406f-8da3-659746c8ff57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.49.0)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.11/site-packages (3.3.2)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.29.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets) (3.11.13)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.56.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (101 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (10.2.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (2.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2025.1)\n",
      "Downloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.56.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Downloading kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.56.0 kiwisolver-1.4.8 matplotlib-3.10.1 pyparsing-3.2.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install transformers datasets matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8c689b21-2028-4566-86cf-ddcd3a9180c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-410m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "99e0e5e8-7293-48c9-863b-ebcf2fa5e9e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading dataset from 'data/modelscope': Directory data/modelscope is neither a `Dataset` directory nor a `DatasetDict` directory.\n",
      "1) Dataset: ewt.pyth.512.-1, Length: 1438\n",
      "Data Peek: dict_keys(['Number', 'Mood', 'Tense', 'VerbForm', 'PronType', 'Person', 'NumType', 'Voice', 'Gender', 'eos', 'first_eos', 'upos', 'dep', 'head', 'within_compound_token_ix', 'max_compound_token_ix', 'tokens', 'doc_id', 'split', 'position', 'upos_NOUN|probe_indices', 'upos_NOUN|probe_classes', 'upos_PUNC|probe_indices', 'upos_PUNC|probe_classes', 'upos_ADP|probe_indices', 'upos_ADP|probe_classes', 'upos_NUM|probe_indices', 'upos_NUM|probe_classes', 'upos_SYM|probe_indices', 'upos_SYM|probe_classes', 'upos_SCONJ|probe_indices', 'upos_SCONJ|probe_classes', 'upos_ADJ|probe_indices', 'upos_ADJ|probe_classes', 'upos_DET|probe_indices', 'upos_DET|probe_classes', 'upos_CCONJ|probe_indices', 'upos_CCONJ|probe_classes', 'upos_PROPN|probe_indices', 'upos_PROPN|probe_classes', 'upos_PRON|probe_indices', 'upos_PRON|probe_classes', 'upos_X|probe_indices', 'upos_X|probe_classes', 'upos_ADV|probe_indices', 'upos_ADV|probe_classes', 'upos_INTJ|probe_indices', 'upos_INTJ|probe_classes', 'upos_VERB|probe_indices', 'upos_VERB|probe_classes', 'upos_AUX|probe_indices', 'upos_AUX|probe_classes', 'dep_acl|probe_indices', 'dep_acl|probe_classes', 'dep_acl:relcl|probe_indices', 'dep_acl:relcl|probe_classes', 'dep_advcl|probe_indices', 'dep_advcl|probe_classes', 'dep_advmod|probe_indices', 'dep_advmod|probe_classes', 'dep_amod|probe_indices', 'dep_amod|probe_classes', 'dep_appos|probe_indices', 'dep_appos|probe_classes', 'dep_aux|probe_indices', 'dep_aux|probe_classes', 'dep_aux:pass|probe_indices', 'dep_aux:pass|probe_classes', 'dep_case|probe_indices', 'dep_case|probe_classes', 'dep_cc|probe_indices', 'dep_cc|probe_classes', 'dep_ccomp|probe_indices', 'dep_ccomp|probe_classes', 'dep_compound|probe_indices', 'dep_compound|probe_classes', 'dep_conj|probe_indices', 'dep_conj|probe_classes', 'dep_cop|probe_indices', 'dep_cop|probe_classes', 'dep_det|probe_indices', 'dep_det|probe_classes', 'dep_flat|probe_indices', 'dep_flat|probe_classes', 'dep_list|probe_indices', 'dep_list|probe_classes', 'dep_mark|probe_indices', 'dep_mark|probe_classes', 'dep_nmod|probe_indices', 'dep_nmod|probe_classes', 'dep_nmod:poss|probe_indices', 'dep_nmod:poss|probe_classes', 'dep_nsubj|probe_indices', 'dep_nsubj|probe_classes', 'dep_nsubj:pass|probe_indices', 'dep_nsubj:pass|probe_classes', 'dep_nummod|probe_indices', 'dep_nummod|probe_classes', 'dep_obj|probe_indices', 'dep_obj|probe_classes', 'dep_obl|probe_indices', 'dep_obl|probe_classes', 'dep_parataxis|probe_indices', 'dep_parataxis|probe_classes', 'dep_punct|probe_indices', 'dep_punct|probe_classes', 'dep_root|probe_indices', 'dep_root|probe_classes', 'dep_xcomp|probe_indices', 'dep_xcomp|probe_classes', 'VerbForm_Fin|probe_indices', 'VerbForm_Fin|probe_classes', 'VerbForm_Inf|probe_indices', 'VerbForm_Inf|probe_classes', 'VerbForm_Ger|probe_indices', 'VerbForm_Ger|probe_classes', 'VerbForm_Part|probe_indices', 'VerbForm_Part|probe_classes', 'PronType_Art|probe_indices', 'PronType_Art|probe_classes', 'PronType_Dem|probe_indices', 'PronType_Dem|probe_classes', 'PronType_Prs|probe_indices', 'PronType_Prs|probe_classes', 'PronType_Rel|probe_indices', 'PronType_Rel|probe_classes', 'PronType_Int|probe_indices', 'PronType_Int|probe_classes', 'Person_1|probe_indices', 'Person_1|probe_classes', 'Person_2|probe_indices', 'Person_2|probe_classes', 'Person_3|probe_indices', 'Person_3|probe_classes', 'Gender_Masc|probe_indices', 'Gender_Masc|probe_classes', 'Gender_Fem|probe_indices', 'Gender_Fem|probe_classes', 'Gender_Neut|probe_indices', 'Gender_Neut|probe_classes', 'Number_Plur|probe_indices', 'Number_Plur|probe_classes', 'Mood_Imp|probe_indices', 'Mood_Imp|probe_classes', 'Tense_Past|probe_indices', 'Tense_Past|probe_classes', 'NumType_Card|probe_indices', 'NumType_Card|probe_classes', 'Voice_Pass|probe_indices', 'Voice_Pass|probe_classes', 'eos_True|probe_indices', 'eos_True|probe_classes', 'first_eos_True|probe_indices', 'first_eos_True|probe_classes'])\n",
      "_________________________\n",
      "2) Dataset: latex.pyth.1024.-1, Length: 4486\n",
      "Data Peek: dict_keys(['tokens', 'is_frac|probe_indices', 'is_frac|probe_classes', 'is_frac|valid_indices', 'is_numerator|probe_indices', 'is_numerator|probe_classes', 'is_numerator|valid_indices', 'is_denominator|probe_indices', 'is_denominator|probe_classes', 'is_denominator|valid_indices', 'is_title|probe_indices', 'is_title|probe_classes', 'is_title|valid_indices', 'is_abstract|probe_indices', 'is_abstract|probe_classes', 'is_abstract|valid_indices', 'is_author|probe_indices', 'is_author|probe_classes', 'is_author|valid_indices', 'is_subscript|probe_indices', 'is_subscript|probe_classes', 'is_subscript|valid_indices', 'is_superscript|probe_indices', 'is_superscript|probe_classes', 'is_superscript|valid_indices', 'is_reference|probe_indices', 'is_reference|probe_classes', 'is_reference|valid_indices', 'is_math|probe_indices', 'is_math|probe_classes', 'is_math|valid_indices', 'is_inline_math|probe_indices', 'is_inline_math|probe_classes', 'is_inline_math|valid_indices', 'is_display_math|probe_indices', 'is_display_math|probe_classes', 'is_display_math|valid_indices', 'start_math|probe_indices', 'start_math|probe_classes', 'start_math|valid_indices', 'end_math|probe_indices', 'end_math|probe_classes', 'end_math|valid_indices'])\n",
      "_________________________\n",
      "3) Dataset: compound_words.pyth.24.-1, Length: 167959\n",
      "Data Peek: dict_keys(['tokens', 'label', 'feature_name'])\n",
      "_________________________\n",
      "4) Dataset: distribution_id.pyth.512.-1, Length: 8413\n",
      "Data Peek: dict_keys(['text', 'meta', 'all_tokens', 'tokens', 'distribution', 'probe_indices', 'valid_indices'])\n",
      "_________________________\n",
      "5) Dataset: natural_lang_id.pyth.512.-1, Length: 28084\n",
      "Data Peek: dict_keys(['lang', 'tokens', 'class_ids', 'probe_indices', 'valid_indices'])\n",
      "_________________________\n",
      "6) Dataset: text_features.pyth.256.10000, Length: 10000\n",
      "Data Peek: dict_keys(['text', 'meta', 'all_tokens', 'tokens', 'contains_digit|probe_indices', 'contains_digit|probe_classes', 'all_digits|probe_indices', 'all_digits|probe_classes', 'contains_capital|probe_indices', 'contains_capital|probe_classes', 'leading_capital|probe_indices', 'leading_capital|probe_classes', 'all_capitals|probe_indices', 'all_capitals|probe_classes', 'contains_whitespace|probe_indices', 'contains_whitespace|probe_classes', 'has_leading_space|probe_indices', 'has_leading_space|probe_classes', 'no_leading_space_and_loweralpha|probe_indices', 'no_leading_space_and_loweralpha|probe_classes', 'contains_all_whitespace|probe_indices', 'contains_all_whitespace|probe_classes', 'is_not_alphanumeric|probe_indices', 'is_not_alphanumeric|probe_classes', 'is_not_ascii|probe_indices', 'is_not_ascii|probe_classes'])\n",
      "_________________________\n",
      "7) Dataset: programming_lang_id.pyth.512.100, Length: 71\n",
      "Data Peek: dict_keys(['text', 'meta', 'lang_prob', 'lang', 'all_tokens', 'tokens', 'class_ids', 'probe_indices', 'valid_indices'])\n",
      "_________________________\n",
      "8) Dataset: wikidata_sorted_is_alive.pyth.128.6000, Length: 6000\n",
      "Data Peek: dict_keys(['tokens', 'name', 'text', 'name_index_start', 'name_index_end', 'surname_index_start', 'surname_index_end', 'class'])\n",
      "_________________________\n",
      "9) Dataset: wikidata_sorted_occupation.pyth.128.6000, Length: 5980\n",
      "Data Peek: dict_keys(['tokens', 'name', 'text', 'name_index_start', 'name_index_end', 'surname_index_start', 'surname_index_end', 'class'])\n",
      "_________________________\n",
      "10) Dataset: wikidata_sorted_sex_or_gender.pyth.128.6000, Length: 6000\n",
      "Data Peek: dict_keys(['tokens', 'name', 'text', 'name_index_start', 'name_index_end', 'surname_index_start', 'surname_index_end', 'class'])\n",
      "_________________________\n",
      "11) Dataset: wikidata_sorted_political_party.pyth.128.3000, Length: 3000\n",
      "Data Peek: dict_keys(['tokens', 'name', 'text', 'name_index_start', 'name_index_end', 'surname_index_start', 'surname_index_end', 'class'])\n",
      "_________________________\n",
      "12) Dataset: wikidata_sorted_occupation_athlete.pyth.128.5000, Length: 5000\n",
      "Data Peek: dict_keys(['tokens', 'name', 'text', 'name_index_start', 'name_index_end', 'surname_index_start', 'surname_index_end', 'class'])\n",
      "_________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_from_disk\n",
    "\n",
    "# Replace this with the path to your base directory containing dataset directories.\n",
    "base_dir = \"data\"\n",
    "count = 1\n",
    "# Iterate over every item in the base directory.\n",
    "peek = []\n",
    "targets = ['','', '', 'feature_name', 'distribution','class_ids','contains_digit|probe_classes','class_ids', 'class','class','class','class','class']\n",
    "for dataset_name in os.listdir(base_dir):\n",
    "    dataset_path = os.path.join(base_dir, dataset_name)\n",
    "    # Check if the item is a directory.\n",
    "    if os.path.isdir(dataset_path):\n",
    "        try:\n",
    "            # Load the dataset from the directory.\n",
    "            ds = load_from_disk(dataset_path)\n",
    "            print(f\"{count}) Dataset: {dataset_name}, Length: {len(ds)}\")\n",
    "            #a = set()\n",
    "            #if targets[count]:\n",
    "            #    for p in ds:\n",
    "            #        a.add(p[targets[count]])\n",
    "            #print('Classes:', a)\n",
    "            print('Data Peek:', ds[0].keys())\n",
    "            print('_'*25)\n",
    "            count += 1\n",
    "            peek.append(ds)\n",
    "            # Iterate over the splits (e.g., train, test, validation) and print their lengths.\n",
    "            #for split, split_dataset in ds.items():\n",
    "            #    print(f\"  {split} split length: {len(split_dataset)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading dataset from '{dataset_path}': {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861654c6-b961-4bd0-baed-b5a268cc9b67",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Wikipedia Sex Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73ebd0d1-44a8-4782-bcad-0b6883437c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset 6000\n"
     ]
    }
   ],
   "source": [
    "data = peek[9]\n",
    "print('Length of dataset', len(data))\n",
    "unique_count = {}\n",
    "unique_keys = set()\n",
    "for d in data:\n",
    "    unique_count[d['class']] = unique_count.get(d['class'], 0) + 1\n",
    "    unique_keys.update(d.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5df3d4a6-8761-41c6-a137-8f9cc6830876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'female': 3000, 'male': 3000}\n",
      "{'surname_index_start', 'name', 'name_index_start', 'surname_index_end', 'tokens', 'name_index_end', 'text', 'class'}\n"
     ]
    }
   ],
   "source": [
    "print(unique_count)\n",
    "print(unique_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6babdfe3-744d-4e38-b3db-f928c7d8e8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name Tokens [124, 125, 126, 127]\n",
      "{'tokens': tensor([    0,   611,  9314,    73,   710,   187,   187,  3378,  6553,   932,\n",
      "          187,  8639,   253, 14811,   187, 16543,  2071,   750,  8947, 19167,\n",
      "          250, 26248,   407, 50276,    47,   324,   571, 20361,   263,   375,\n",
      "         4530,   187,   473, 32612,  1351, 30354,   249, 19167,   250, 26248,\n",
      "          407, 50276,   127,   218,    66, 14437,  4123,   378,  3090,    90,\n",
      "        42664,   518,  3314,   333,   187,  1623,    84,   500, 12424,   321,\n",
      "        19167,   250, 26248,   407, 50276,  3864,   343,   460,  6935,    80,\n",
      "          460,   187, 24131,  1950,  2072, 22509,  7090,   729,  1757, 19167,\n",
      "          250, 26248,   407, 50276,  7638,  8440,   388,  2269,   462,   187,\n",
      "        15590,  2044,    66,   418,   554,  5756,  7381, 19167,   250, 26248,\n",
      "          407, 50276, 18552,    66,  4051,  1506,   187, 47831,  3044,    41,\n",
      "         1079, 19167,   250, 26248,   407, 50276,    44,   727, 45955,   611,\n",
      "         6002,    77,  8947,   187, 34781, 12951,  2651, 14573]), 'name': 'Monica Niculescu', 'text': ' Kerkhove\\n\\nWithdrawals\\nBefore the tournament\\n Anna Blinkova →replaced by  Nadia Podoroska\\n Océane Dodin →replaced by  Çağla Büyükakçay\\n Ons Jabeur →replaced by  Quirine Lemoine\\n Kristína Kučová →replaced by  Polona Hercog\\n Varvara Lepchenko →replaced by  Alexa Glatch\\n Christina McHale →replaced by  Kateryna Kozlova\\n Monica Niculescu', 'name_index_start': 124, 'name_index_end': 127, 'surname_index_start': 125, 'surname_index_end': 127, 'class': 'female'}\n",
      "_________________________\n",
      "tensor([34781, 12951,  2651, 14573])\n",
      "_________________________\n",
      "| Monica Niculescu|\n"
     ]
    }
   ],
   "source": [
    "sample = data[5999]\n",
    "\n",
    "name_range = list(range(sample['name_index_start'],sample['name_index_end']+1))\n",
    "print('Name Tokens',name_range)\n",
    "print(sample)\n",
    "print('_'*25)\n",
    "print(sample['tokens'][name_range])\n",
    "print('_'*25)\n",
    "print(f\"|{tokenizer.decode(sample['tokens'][name_range])}|\")\n",
    "#print('_'*25)\n",
    "#print(sample['text'][name_range])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb79fe59-cbfe-4968-8db1-9d4828ae4b37",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Wikipedia Political Party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "008298f2-42d2-48d8-9ff0-2d6f7fcdf21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset 3000\n"
     ]
    }
   ],
   "source": [
    "data = peek[10]\n",
    "print('Length of dataset', len(data))\n",
    "unique_count = {}\n",
    "unique_keys = set()\n",
    "for d in data:\n",
    "    unique_count[d['class']] = unique_count.get(d['class'], 0) + 1\n",
    "    unique_keys.update(d.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ae8f733-b703-4226-96ee-66cedd429844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Democratic Party': 1500, 'Republican Party': 1500}\n",
      "{'name_index_start', 'text', 'name', 'surname_index_start', 'name_index_end', 'tokens', 'surname_index_end', 'class'}\n"
     ]
    }
   ],
   "source": [
    "print(unique_count)\n",
    "print(unique_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3858a46-8ddd-44a1-ac4a-40c5573a47c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name Tokens [124, 125, 126, 127]\n",
      "{'tokens': tensor([    0,   417,   795,    36,    15,    52,    15, 13054,    64, 12062,\n",
      "         2167,   767,   390,   625,  3302,    84,   943,   417,   320,  4136,\n",
      "          281,  2740,   689,  1386, 47834,    13,  4543,   943,   667,  3302,\n",
      "           84,   320,  9070,   432,   253, 38213,   689,   247,  1386,   390,\n",
      "         3239,    15,  1310,   247,  1436,   434,  3302,    84,   403,  7744,\n",
      "          908,   347,   247, 34826,    13,   873,  1110,  3302,    84,  1293,\n",
      "         8470,   390,  9894,   313, 10328,   347,   795,    49,    43,    64,\n",
      "          323,   795,    49,    15,   500,    15,  1503,  9631,  6148,    64,\n",
      "        13441,   187,   187,    34,  1643,   973,    14,  4304,  8442,   403,\n",
      "         3636,   407,   616,  3302,    84,  3815,    13,   824,   347,   795,\n",
      "           39,  4976,    64,   313, 20655,  3642,  6304,  4692, 21519,   582,\n",
      "          795,    40,  4449,    64,   313, 23108, 22547, 24999,   582,   795,\n",
      "           43, 27168,    64,   313,  8732,   401,    15, 16598]), 'name': 'John F. Kennedy', 'text': \" not _C.S. Lewis_ ), though two or more initials should not be allowed to break over line endings, nor should any initials be separated from the surname over a line or page. If a person's initials are commonly used as a nickname, set those initials without spaces or periods (such as _PJ_ for _P. J. Zondervan_ ).\\n\\nA few well-known figures are identified by their initials alone, such as _FDR_ (Franklin Delano Roosevelt), _GBS_ (George Bernard Shaw), _JFK_ (John F. Kennedy\", 'name_index_start': 124, 'name_index_end': 127, 'surname_index_start': 125, 'surname_index_end': 127, 'class': 'Democratic Party'}\n",
      "_________________________\n",
      "tensor([ 8732,   401,    15, 16598])\n",
      "_________________________\n",
      "|John F. Kennedy|\n"
     ]
    }
   ],
   "source": [
    "sample = data[5]\n",
    "\n",
    "name_range = list(range(sample['name_index_start'],sample['name_index_end']+1))\n",
    "print('Name Tokens',name_range)\n",
    "print(sample)\n",
    "print('_'*25)\n",
    "print(sample['tokens'][name_range])\n",
    "print('_'*25)\n",
    "print(f\"|{tokenizer.decode(sample['tokens'][name_range])}|\")\n",
    "#print('_'*25)\n",
    "#print(sample['text'][name_range])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86676831-b010-4eac-9a86-3349dd70ae0e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Wikipedia Athlete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f1f5c99-bfa2-408d-8f81-f5c3d28e1a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset 5000\n"
     ]
    }
   ],
   "source": [
    "data = peek[11]\n",
    "print('Length of dataset', len(data))\n",
    "unique_count = {}\n",
    "unique_keys = set()\n",
    "for d in data:\n",
    "    unique_count[d['class']] = unique_count.get(d['class'], 0) + 1\n",
    "    unique_keys.update(d.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "358ca995-ac5e-46c3-a0a0-9c844d108eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'association football player': 1000, 'basketball player': 1000, 'baseball player': 1000, 'American football player': 1000, 'ice hockey player': 1000}\n",
      "{'name_index_start', 'text', 'name', 'surname_index_start', 'name_index_end', 'tokens', 'surname_index_end', 'class'}\n"
     ]
    }
   ],
   "source": [
    "print(unique_count)\n",
    "print(unique_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e43e057-ca3c-4ee2-96f5-eece5178e943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name Tokens [126, 127]\n",
      "{'tokens': tensor([    0,   380,  4983,  7145,  2135,  2628,  7285,  7528, 10422,   310,\n",
      "          671,  1527,    15, 26783, 13648,  3227,   939, 28589,  1160,   521,\n",
      "         3963,  2952, 11386,   323,   253,  5453,    13,  2403,   271,  3486,\n",
      "          281,   253, 19928,   273, 10909, 26575, 11433,   327,  1283, 15814,\n",
      "          285,  9073, 14393,   253,  2165,  1066,   253, 13726,    15,   187,\n",
      "          187,  1898,  1223,  1841,  2427,   247,  2372, 19273, 22302,   323,\n",
      "          731,  1390,  2952,    13,   597,   457,   250,  1335,  1077, 21220,\n",
      "           15,  7539,    42,   816,   871,   344,   457,    84,   581,   273,\n",
      "          253,  1755,  1458, 21220,  7150, 12270,   275,   253,  9728,    13,\n",
      "          275,   619,  4743,    15,  3105,   816,   275, 13946,  8238,    13,\n",
      "          533,  1475,   253,  2644,  1986,  2077,    13,  6234,   344,   753,\n",
      "           15,   495,    15,  1722,    13,  4240, 18626,  2239,  2239,    56,\n",
      "         7871,  2968,   342,  6166,  5360,   454, 39993,  7902]), 'name': 'Dave Johnson', 'text': ' The starting cornerback job opposite Breaux is also open. RB Marshawn Lynch made his regular season debut for the club, making an impact to the tune of 76 rushing yards on 18 carries and helping seal the game down the stretch.\\n\\nAnd while things went a bit haywire for them last season, they’re still very talented. «I just know he’s one of the top 15 talented quarterbacks in the league, in my opinion. Not just in NFL cities, but around the whole United States,» he said. 3. 17, 2017″ > >W signs deal with Under ArmourDave Johnson', 'name_index_start': 126, 'name_index_end': 127, 'surname_index_start': 127, 'surname_index_end': 127, 'class': 'basketball player'}\n",
      "_________________________\n",
      "tensor([39993,  7902])\n",
      "_________________________\n",
      "|Dave Johnson|\n"
     ]
    }
   ],
   "source": [
    "sample = data[2500]\n",
    "\n",
    "name_range = list(range(sample['name_index_start'],sample['name_index_end']+1))\n",
    "print('Name Tokens',name_range)\n",
    "print(sample)\n",
    "print('_'*25)\n",
    "print(sample['tokens'][name_range])\n",
    "print('_'*25)\n",
    "print(f\"|{tokenizer.decode(sample['tokens'][name_range])}|\")\n",
    "#print('_'*25)\n",
    "#print(sample['text'][name_range])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ec7d03-8797-4eb4-b14e-2834f8c14962",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Alive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "75a0a2b2-566d-4052-aecd-f45ae8a24710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset 6000\n",
      "{'true': 3000, 'false': 3000}\n",
      "{'name_index_start', 'text', 'name', 'surname_index_start', 'name_index_end', 'tokens', 'surname_index_end', 'class'}\n"
     ]
    }
   ],
   "source": [
    "data = peek[7]\n",
    "print('Length of dataset', len(data))\n",
    "unique_count = {}\n",
    "unique_keys = set()\n",
    "for d in data:\n",
    "    unique_count[d['class']] = unique_count.get(d['class'], 0) + 1\n",
    "    unique_keys.update(d.keys())\n",
    "\n",
    "print(unique_count)\n",
    "print(unique_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a06569d9-c7e6-4b52-9692-89f2e8808784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name Tokens [35, 36, 37]\n",
      "{'tokens': tensor([    0,    46, 46929,   556, 26582, 31734,    15,  2053,   513,   417,\n",
      "         4833, 21977,  2600,    13,  2167,   353, 46929,   778,  6233, 36662,\n",
      "          323,  3580,  9716,  3066, 26582,  4859,    15,   187,   187, 13117,\n",
      "        17416,  1511, 11412,   187,   187, 40616,   443, 12727,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0]), 'name': 'Lady Gaga', 'text': 'Meredith has affiliate partnerships. These do not influence editorial content, though Meredith may earn commissions for products purchased via affiliate links.\\n\\nJoanne type Music\\n\\nLady Gaga<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>', 'name_index_start': 35, 'name_index_end': 37, 'surname_index_start': 36, 'surname_index_end': 37, 'class': 'true'}\n",
      "_________________________\n",
      "tensor([40616,   443, 12727])\n",
      "_________________________\n",
      "|Lady Gaga|\n"
     ]
    }
   ],
   "source": [
    "sample = data[0]\n",
    "\n",
    "name_range = list(range(sample['name_index_start'],sample['name_index_end']+1))\n",
    "print('Name Tokens',name_range)\n",
    "print(sample)\n",
    "print('_'*25)\n",
    "print(sample['tokens'][name_range])\n",
    "print('_'*25)\n",
    "print(f\"|{tokenizer.decode(sample['tokens'][name_range])}|\")\n",
    "#print('_'*25)\n",
    "#print(sample['text'][name_range])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347b9f5d-df76-462d-8c18-264b8214d750",
   "metadata": {},
   "source": [
    "## Occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "16f7af8a-f2f9-41f4-ac16-65aa132dfae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset 5980\n",
      "{'singer': 1000, 'actor': 1000, 'politician': 1000, 'journalist': 1000, 'athlete': 1000, 'researcher': 980}\n",
      "{'name_index_start', 'text', 'name', 'surname_index_start', 'name_index_end', 'tokens', 'surname_index_end', 'class'}\n"
     ]
    }
   ],
   "source": [
    "data = peek[8]\n",
    "print('Length of dataset', len(data))\n",
    "unique_count = {}\n",
    "unique_keys = set()\n",
    "for d in data:\n",
    "    unique_count[d['class']] = unique_count.get(d['class'], 0) + 1\n",
    "    unique_keys.update(d.keys())\n",
    "\n",
    "print(unique_count)\n",
    "print(unique_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "16200c0f-b37e-4eda-aca2-65adb25dfad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name Tokens [126, 127]\n",
      "{'tokens': tensor([    0,   745,   342,   253, 14511,    15, 17814,   310,  1024, 13644,\n",
      "        29075,  3006,   670,   849, 16922, 21088,  7902,   457,    84,  7185,\n",
      "          285,   611,  1279,    70,  4255,   457,    84,   773,  4924,  1869,\n",
      "          668,   588, 42620,  2806, 11163,   689,   281,   253,  8786,  7021,\n",
      "           15,   535,   187,   688,   271,  1121,    14,   264,   323,   253,\n",
      "        17372,  7648,  5687, 18879,    13,   773, 16008,  3778,  1680,   411,\n",
      "         3288,   272,  5418,   657,   302,   398,   285, 43779,   253,  9922,\n",
      "         7021,  1806, 33614,  2955,   282, 32920, 12013,    27,   187,   187,\n",
      "        16008,  3778,   310, 42547,   387,  1633,  1643,   952,  1869,  1896,\n",
      "           15,   754,   310,  2970,   690,  2806,   952,   281,  7277,   779,\n",
      "          281, 22306,  6729,    15,  6729,  1904,   457,    85,   755, 16922,\n",
      "         7902,   562,   273, 12907,    15,  6729,  1904,   457,    85, 34030,\n",
      "         5332,   544, 32336,  1092,  1014,  2167, 11290, 32574]), 'name': 'Ken Burns', 'text': ' off with the narrative. Everyone is now publicly theorizing about how Alice Marie Johnson’s freedom and Kanye West’s “free thought” will lure black voters over to the Republican Party.\\n\\n\\nIn an op-ed for the Detroit Free Press titled, “Donald Trump Is Wooing Black Voters and Killing the Democratic Party,” Rochelle Riley writes:\\n\\nDonald Trump is succeeding at something few people thought possible. He is getting some black people to compare him to Barack Obama. Obama didn’t get Alice Johnson out of jail. Obama didn’t pardon Jack [Johnson], even though Ken Burns', 'name_index_start': 126, 'name_index_end': 127, 'surname_index_start': 127, 'surname_index_end': 127, 'class': 'actor'}\n",
      "_________________________\n",
      "tensor([11290, 32574])\n",
      "_________________________\n",
      "| Ken Burns|\n"
     ]
    }
   ],
   "source": [
    "sample = data[2000]\n",
    "\n",
    "name_range = list(range(sample['name_index_start'],sample['name_index_end']+1))\n",
    "print('Name Tokens',name_range)\n",
    "print(sample)\n",
    "print('_'*25)\n",
    "print(sample['tokens'][name_range])\n",
    "print('_'*25)\n",
    "print(f\"|{tokenizer.decode(sample['tokens'][name_range])}|\")\n",
    "#print('_'*25)\n",
    "#print(sample['text'][name_range])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f3c1eb-2bb2-46b4-bcca-ee8bcbf6b43d",
   "metadata": {},
   "source": [
    "## Natural Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "63dafe0e-d896-41c1-9690-59438abd196f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset 28084\n",
      "{4: 3137, 9: 3097, 2: 3090, 1: 3102, 3: 3126, 7: 2967, 5: 3155, 8: 3110, 6: 3300}\n",
      "{'class_ids', 'lang', 'probe_indices', 'tokens', 'valid_indices'}\n"
     ]
    }
   ],
   "source": [
    "data = peek[4]\n",
    "print('Length of dataset', len(data))\n",
    "unique_count = {}\n",
    "unique_keys = set()\n",
    "for d in data:\n",
    "    unique_count[d['class_ids'].item()] = unique_count.get(d['class_ids'].item(), 0) + 1\n",
    "    unique_keys.update(d.keys())\n",
    "\n",
    "print(unique_count)\n",
    "print(unique_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "416a8bef-3e3c-485d-8ea9-88fc33a3741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [d['valid_indices'].shape[0] for d in data]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d12fd718-2788-4a9a-a92c-7d96922973dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " 510,\n",
       " ...]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7ab5a50d-45fe-42b2-9e54-90b54cae8a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________\n",
      "Tokens shape torch.Size([512])\n",
      "Valid indices shape torch.Size([510])\n",
      "_________________________\n",
      "Decoded tokens at valid indices :  kijken.\n",
      "Wat betreft de duur van een bevoegdheidsdelegatie, verwelkomen wij en staan wij helemaal achter de idee van stilzwijgende verlenging, zoals dat in het verslag onder woorden is gebracht, want wij vinden dit zeer constructief, en we kunnen melden dat enkele van dit soort oplossingen al in diverse wetgevingsdocumenten voorkomen.\n",
      "Ik heb nog een andere specifieke opmerking over de bezwaarperiode. Ook hier moet ik zeggen dat we met één stem spreken, want wij delen ook grotendeels het standpunt van de rapporteur betreffende de standaardformulering van twee maanden, met de mogelijkheid van verlenging met nog eens twee maanden, wat zou kunnen worden vastgelegd in een gemeenschappelijke overeenkomst tussen onze drie instellingen, die we in de toekomst hopelijk zullen krijgen. Ik geloof dat we in het huidige wetgevingswerk al circa tien positieve voorbeelden hebben gezien van de manier waarop dit is toegepast.\n",
      "Wat betreft de urgentieprocedure, hebben we in het verleden al enkele duidelijke voorbeelden gezien van problemen met betrekking tot bijvoorbeeld de voedselveiligheid of de veiligheid van speelgoed die soms vragen om een zeer snelle procedure, en daarom denken we dat we nog iets snellers moeten vinden dan de door de rapporteur voorgestelde vroegtijdige verklaring van geen bezwaar.\n",
      "Ik wil graag afsluiten met een opmerking over de aanpassing, omdat dit heel belangrijk is voor het Parlement. Ook hier zijn wij voorstander van de pragmatische aanpak, want dit Parlement heeft, samen met de Commissie, al een aanzienlijke hoeveelheid werk verricht voor de aanpassing van meer dan 250 wetgevende basisbesluiten, die\n",
      "_________________________\n",
      "Tokens at probe index: tensor([10549,   293])\n",
      "Decoded tokens at probe index:\n",
      "| hier|\n",
      "|el|\n",
      "class index: tensor(4)\n"
     ]
    }
   ],
   "source": [
    "sample = data[1]\n",
    "\n",
    "print('_'*25)\n",
    "print('Tokens shape',sample['tokens'].shape)\n",
    "print('Valid indices shape', sample['valid_indices'].shape)\n",
    "print('_'*25)\n",
    "print('Decoded tokens at valid indices :',tokenizer.decode(sample['tokens'][sample['valid_indices']]))\n",
    "print('_'*25)\n",
    "print('Tokens at probe index:',sample['tokens'][sample['probe_indices']])\n",
    "print('Decoded tokens at probe index:')\n",
    "for t in sample['tokens'][sample['probe_indices']]:\n",
    "    print(f\"|{tokenizer.decode(t)}|\")\n",
    "print('class index:',sample['class_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0a8f3dfb-294e-4b54-ab16-2434941528e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
       "         15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
       "         29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
       "         43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
       "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
       "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
       "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
       "         99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
       "        113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
       "        127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,\n",
       "        141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,\n",
       "        155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
       "        183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
       "        197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
       "        211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224,\n",
       "        225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
       "        239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
       "        253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266,\n",
       "        267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280,\n",
       "        281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294,\n",
       "        295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308,\n",
       "        309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322,\n",
       "        323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336,\n",
       "        337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
       "        351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364,\n",
       "        365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378,\n",
       "        379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392,\n",
       "        393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
       "        407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420,\n",
       "        421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434,\n",
       "        435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448,\n",
       "        449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462,\n",
       "        463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476,\n",
       "        477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490,\n",
       "        491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504,\n",
       "        505, 506, 507, 508, 509, 510])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['valid_indices']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6321bca-032d-40a7-a38b-369aa146429b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Dataset Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13ca6f01-6b6b-47bd-ad12-49fa5e88d166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = peek[9]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4798b753-85b9-40dc-86fb-cc2249097aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub = data.select(list(range(1000,1438)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b17fa9d0-4531-4c0a-9017-ccd1f7cc8c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': tensor([    0,   326,  6351,  3486,   949,   253, 35240,   789,   908,   281,\n",
       "         17093,   731,    15,   187,   187,    34, 19718, 16222,   281,  1445,\n",
       "           275,   399,   373,  3354,  3936,   441,   896,   247,  3213,   275,\n",
       "           673,    13,   281,   253,  1107,   816,  1078,   285,   846,  3645,\n",
       "          3660,   309,    13,   672,   253,  2846,   369,  1728,   281,   247,\n",
       "          1387,   273, 10846,   665,  1925,  3746,  9362,  2652,  3090, 33144,\n",
       "            13,   253, 15454,    15,  2596,   273,   616,  7342,   369,   281,\n",
       "         16497,  1270,  5685,  1445,   273,   253,  2469,  1905,  1219,  3381,\n",
       "         12914,   399,  3090,  6554,    13, 22838, 45374,   607,  1905,   715,\n",
       "           253,  3448,   273,  1246,    15,   496,   253,  1232,    13,   597,\n",
       "         14257, 23179, 18299,  1204,    15,   187,   187,   688,   253, 18471,\n",
       "            84,    13,   597,   574,  2323,    28,   368,   755,   247,  3282,\n",
       "           273,   436,   275, 41888, 45681, 20799,   348,  1216]),\n",
       " 'name': 'Ernst Ludwig Kirchner',\n",
       " 'text': ' that gain impact through the astonishing work used to illustrate them.\\n\\nA gallery devoted to art in Dresden takes us back a step in time, to the years just before and after World War I, when the city was home to a group of artists who called themselves Die Brücke, the Bridge. One of their goals was to translate great German art of the past — Albrecht Dürer, Lucas Cranach — into the language of present. In the process, they virtually invented Expressionism.\\n\\nIn the 1920s, they had success; you get a sense of this in Ernst Ludwig Kirchner',\n",
       " 'name_index_start': 123,\n",
       " 'name_index_end': 127,\n",
       " 'surname_index_start': 124,\n",
       " 'surname_index_end': 127,\n",
       " 'class': 'male'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sub[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1716f56b-c528-44d2-a042-a30b991598a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': tensor([    0,   326,  6351,  3486,   949,   253, 35240,   789,   908,   281,\n",
       "         17093,   731,    15,   187,   187,    34, 19718, 16222,   281,  1445,\n",
       "           275,   399,   373,  3354,  3936,   441,   896,   247,  3213,   275,\n",
       "           673,    13,   281,   253,  1107,   816,  1078,   285,   846,  3645,\n",
       "          3660,   309,    13,   672,   253,  2846,   369,  1728,   281,   247,\n",
       "          1387,   273, 10846,   665,  1925,  3746,  9362,  2652,  3090, 33144,\n",
       "            13,   253, 15454,    15,  2596,   273,   616,  7342,   369,   281,\n",
       "         16497,  1270,  5685,  1445,   273,   253,  2469,  1905,  1219,  3381,\n",
       "         12914,   399,  3090,  6554,    13, 22838, 45374,   607,  1905,   715,\n",
       "           253,  3448,   273,  1246,    15,   496,   253,  1232,    13,   597,\n",
       "         14257, 23179, 18299,  1204,    15,   187,   187,   688,   253, 18471,\n",
       "            84,    13,   597,   574,  2323,    28,   368,   755,   247,  3282,\n",
       "           273,   436,   275, 41888, 45681, 20799,   348,  1216]),\n",
       " 'name': 'Ernst Ludwig Kirchner',\n",
       " 'text': ' that gain impact through the astonishing work used to illustrate them.\\n\\nA gallery devoted to art in Dresden takes us back a step in time, to the years just before and after World War I, when the city was home to a group of artists who called themselves Die Brücke, the Bridge. One of their goals was to translate great German art of the past — Albrecht Dürer, Lucas Cranach — into the language of present. In the process, they virtually invented Expressionism.\\n\\nIn the 1920s, they had success; you get a sense of this in Ernst Ludwig Kirchner',\n",
       " 'name_index_start': 123,\n",
       " 'name_index_end': 127,\n",
       " 'surname_index_start': 124,\n",
       " 'surname_index_end': 127,\n",
       " 'class': 'male'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5252e3ad-b189-43f4-98f1-ec4470110381",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ef9d762-36ff-4159-bd76-e06420c7a09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2302d812-9373-40e4-a3c7-fa896b31d1a7",
   "metadata": {},
   "source": [
    "## Sparsify Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82090f22-a5e9-49c8-aa00-b3e6f5b07776",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparsify.sparsify import Sae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbdf12fb-b066-4592-9e8b-719855f53803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b34a05ccc343789d03c8894c0e8ad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 49 files:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n"
     ]
    }
   ],
   "source": [
    "saes = Sae.load_many('EleutherAI/sae-pythia-410m-65k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5943cb46-d29c-4380-a618-804bd1a668e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['layers.0.mlp', 'layers.1.mlp', 'layers.2.mlp', 'layers.3.mlp', 'layers.4.mlp', 'layers.5.mlp', 'layers.6.mlp', 'layers.7.mlp', 'layers.8.mlp', 'layers.9.mlp', 'layers.10.mlp', 'layers.11.mlp', 'layers.12.mlp', 'layers.13.mlp', 'layers.14.mlp', 'layers.15.mlp', 'layers.16.mlp', 'layers.17.mlp', 'layers.18.mlp', 'layers.19.mlp', 'layers.20.mlp', 'layers.21.mlp', 'layers.22.mlp', 'layers.23.mlp'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6389d532-41b3-4ffc-afae-751e9bbdf875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d901f3110540c6abe097269b9cc925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dropping extra args {'signed': False}\n"
     ]
    }
   ],
   "source": [
    "sae = Sae.load_from_hub(\"EleutherAI/sae-pythia-410m-65k\", hookpoint=\"layers.22.mlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a1bcc22-2c3c-4bf5-9d4b-b3e601a6c187",
   "metadata": {},
   "outputs": [],
   "source": [
    "sae = sae.to('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4754a349-b95f-4986-ae26-3fa4f6fe51c8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Testing the expected tensor shape in the sae forward method. It is: (inputs, input_embedding) i.e. (batch, seq, embedding) must be reduced to (batch * seq, embedding) before passing through forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "504399d6-e7bc-4ef6-9430-a01dbbf35c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 18, 1024])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand((16,18,1024), device='cuda:0')\n",
    "b = a.view(-1,1024).clone()\n",
    "b_op = sae.forward(b)\n",
    "c = b_op.sae_out.view(16,-1,1024)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dfe8bc0-daca-4a2d-a6df-7aa2ab27a16d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_results = []\n",
    "for i in range(a.shape[1]):\n",
    "    temp_a = a[:,i,:]\n",
    "    #print('Temp A',temp_a.shape)\n",
    "    all_results.append(sae.forward(temp_a).sae_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b6a07e3-0825-4070-938f-7fd06a91012c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 18, 1024])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_prime = torch.stack(all_results,dim=1)\n",
    "c_prime.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acbaf0bb-09e9-447b-a1ef-7162b4e75d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(c, c_prime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fc4bea-9e46-48d6-a7e5-c0444d2d418a",
   "metadata": {},
   "source": [
    "## Testing how (batch, seq, embedding) can be translated into (n, embedding) and back to the (batch, seq, embedding) to maintain position information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a8dfab2-f186-40f7-b17f-381b1889fc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f81e08c3-bb69-4e9b-a49d-909893dfd815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "422"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce718c76-992f-4404-bc27-7ca70736685f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IP shape torch.Size([16, 557, 1024])\n",
      "IP_Mod shape torch.Size([8912, 1024])\n",
      "IP_Prime shape torch.Size([16, 557, 1024])\n",
      "IP == IP_Prime: True\n",
      "_________________________\n",
      "Top Activations: torch.Size([8912, 32]), Top Activations Indices: torch.Size([8912, 32])\n",
      "Top Indices: tensor([ 4353,  8129, 10690, 15770, 15923, 17287, 17367, 26211, 29227, 29277,\n",
      "        32894, 33289, 33903, 36181, 37275, 38507, 38586, 39625, 42146, 42744,\n",
      "        42775, 48749, 49437, 50523, 51627, 51760, 52517, 52868, 56322, 57425,\n",
      "        58835, 28422], device='cuda:0')\n",
      "tensor([ 8.5520,  4.3722, 10.2342,  5.5670,  5.0898,  4.8645,  6.0769,  4.6501,\n",
      "         4.7437,  4.3074,  6.3670,  4.3509,  4.7134,  5.8097,  4.8363,  5.1812,\n",
      "         4.0863,  4.1682,  6.6390,  5.7630,  6.7948,  4.7071,  4.0192,  4.0508,\n",
      "         4.9415,  6.9674,  5.1510,  4.4646,  4.0666,  5.0733,  4.1196,  3.9472],\n",
      "       device='cuda:0')\n",
      "_________________________\n",
      "OP_Mod Shape torch.Size([8912, 1024])\n",
      "OP Shape torch.Size([16, 557, 1024])\n"
     ]
    }
   ],
   "source": [
    "batch = 16\n",
    "\n",
    "ip = torch.rand((batch, torch.randint(100,1000,size=(1,)).item(), 1024), device='cuda:0') # batch, sequence, embedding\n",
    "print('IP shape', ip.shape)\n",
    "ip_mod = einops.rearrange(ip, \"b s e -> (b s) e\")\n",
    "print('IP_Mod shape', ip_mod.shape)\n",
    "ip_prime = einops.rearrange(ip_mod, \"(b s) e -> b s e\", b = batch)\n",
    "print('IP_Prime shape', ip_prime.shape)\n",
    "print('IP == IP_Prime:', torch.allclose(ip_prime, ip))\n",
    "print('_'*25)\n",
    "with torch.no_grad():\n",
    "    enc = sae.encode(ip_mod)\n",
    "    print(f\"Top Activations: {enc.top_acts.shape}, Top Activations Indices: {enc.top_indices.shape}\")\n",
    "    print(\"Top Indices:\", enc.top_indices[0,:])\n",
    "    print(\"Top Activations\", enc.top_acts[0,:])\n",
    "    print('_'*25)\n",
    "    op_mod = sae.decode(*enc)\n",
    "    print(\"OP_Mod Shape\",op_mod.shape)\n",
    "    op = einops.rearrange(ip_mod, \"(b s) e -> b s e\", b = 16)\n",
    "    print(\"OP Shape\", op.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d127d25b-66f9-45f3-84ba-542aa113ee24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8192, 32]), torch.Size([8192, 32]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e2c2d20a-5637-495c-ab16-71011ad880f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  475,  2200,  3976,  4078,  5535,  5780,  6660,  6829,  9490,  9783,\n",
       "        10334, 10656, 11203, 11358, 11713, 12433, 14352, 16603, 19383, 19867,\n",
       "        20635, 21283, 24260, 24993, 28392, 28526, 30227, 30303, 30336, 31305,\n",
       "        31800,  6613], device='cuda:0')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0e3710b5-9245-4599-94e6-5321918bc082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.7005,  1.7695,  3.2423,  1.8509,  1.6629,  3.0474,  1.5182,  2.4735,\n",
       "         1.5209,  1.5189,  2.2650,  1.4994,  3.5307,  1.6637,  1.5109, 11.0463,\n",
       "         2.2309,  2.4835,  1.6456,  1.4765,  1.5123,  2.6469,  2.5875,  2.8152,\n",
       "         1.5593,  1.5475,  1.8769,  4.3661,  1.5953,  1.6941,  2.3382,  1.4640],\n",
       "       device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "67e92b8e-94b1-4bd6-970d-e27784c6006b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8192, 768])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c5d653a4-0fe1-427b-bcb3-39c4f1613680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0msae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_acts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_indices\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mFile:\u001b[0m      /home/mltrain/sparsify/sparsify/sparse_coder.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sae.decode?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6db0497d-4a38-4c25-92b6-040011f45024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-acts torch.Size([8752, 32768])\n",
      "Y torch.Size([8752, 768])\n",
      "sae_out torch.Size([8752, 768])\n",
      "E torch.Size([8752, 768])\n"
     ]
    }
   ],
   "source": [
    "dec = sae.forward(ip_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d9b15327-db53-4a19-915c-cc240dd9778d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32768"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae.cfg.num_latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e42c919b-2fe0-4bbe-9992-bdc4f3ee7717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8752, 768])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec.sae_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1da865a2-78e1-42ff-a6aa-61930a2c92fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8752, 32])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec.latent_acts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "188f93d6-3183-4b2b-ae90-46aa872682d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8752, 32])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec.latent_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "451960b5-2c67-4579-9704-17491987880a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = torch.zeros(8752, 32768, device=dec.latent_acts.device, dtype=dec.latent_acts.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c3476b33-c874-466e-a83f-5f28e2666814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8752, 32768])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "25bfd1da-3931-47cb-b0a3-b1252d1cd1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', dtype=torch.bfloat16,\n",
       "       grad_fn=<ScatterBackward0>)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense.scatter_(1, dec.latent_indices, dec.latent_acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "aace8584-8f8d-445f-998b-34d2d741d1fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8752, 32768])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "862aeace-d8dc-4c32-8471-e829875be213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8752])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(32, device='cuda:0'), tensor(32, device='cuda:0'))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_sum = (dense != 0).sum(dim=-1)\n",
    "print(p_sum.shape)\n",
    "p_sum.min(), p_sum.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2d1e211-59e8-427e-bc38-74eeb4c78dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythia_sae import SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d5bc235-788b-4c60-a0a7-7618ed5b379b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c734fa95d841d588ec3fd354e71698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 50 files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n",
      "Dropping extra args {'signed': False}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 laoded\n",
      "Layer 2 laoded\n",
      "Layer 3 laoded\n"
     ]
    }
   ],
   "source": [
    "sae_handle = SAE(device='cuda:0')\n",
    "sae_handle.load_many(\"EleutherAI/sae-pythia-160m-32k\", layers=[1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5df34646-0682-4c13-a5f2-bd9874b48364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseCoder(\n",
       "  (encoder): Linear(in_features=768, out_features=32768, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae_handle.sae_layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0912d210-8459-4a98-8795-d09cfc3a95e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-acts torch.Size([8192, 32768])\n",
      "Y torch.Size([8192, 768])\n",
      "sae_out torch.Size([8192, 768])\n",
      "E torch.Size([8192, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "ip = torch.rand((16,512,768), device='cuda:0')\n",
    "op, sae_latents = sae_handle.compute_activations(ip, layer=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8e3acb0-6264-4718-bc4a-b02f962595ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 512, 768])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61cc6569-0711-4162-ace9-3c612e98c891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 512, 32768])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae_latents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6beba352-56bc-49d3-b156-fd0c04dd692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_sum = (sae_latents != 0).sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bd571b7-e2bf-4ed9-b056-99b0e5243009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(32, device='cuda:0'), tensor(32, device='cuda:0'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_sum.min(), p_sum.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6acfcf9e-e935-4b4c-a5b2-a1df740a4e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_sample = sae_latents[0, [500,501],:]\n",
    "pos_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9298dec-39d4-46ab-87f8-62883b227e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = pos_sample.mean(dim=-1).cpu().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71b6e515-9413-4936-a18e-cb991b41436a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0081787109375, 0.007293701171875]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "273b927b-d38e-4767-b7f7-818c66429088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(tokenizer.eos_token)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9811d9a9-061c-4332-b868-f71c3adcf7e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
