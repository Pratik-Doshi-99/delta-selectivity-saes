2025-03-18 03:26:52 [MainThread] [INFO] Computing selectivity with the following arguments:
2025-03-18 03:26:52 [MainThread] [INFO] Namespace(device1=None, device2=None, output_directory='results_410m', model_name='EleutherAI/pythia-410m', sae_name='EleutherAI/sae-pythia-410m-65k', datasets='1,4', start_index=0, n_samples=None, batch_size=128, layers='0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23', output_size=1024, num_workers=2, model_hook_template='blocks.<layer>.hook_mlp_out', sae_layer_template='layers.<layer>.mlp')
2025-03-18 03:26:52 [MainThread] [INFO] Will process dataset indices: [1, 4]
2025-03-18 03:26:52 [MainThread] [INFO] Starting dataset 1...
2025-03-18 03:26:52 [MainThread] [INFO] Validating Arguments...
2025-03-18 03:26:52 [MainThread] [INFO] Computing activations with the following arguments:
2025-03-18 03:26:52 [MainThread] [INFO] Namespace(model_name='EleutherAI/pythia-410m', sae_name='EleutherAI/sae-pythia-410m-65k', dataset_idx=1, start_index=0, n_samples=None, device='cuda:0', batch_size=128, layers='0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23', output_size=1024, output_directory='results_410m', num_workers=2, model_hook_template='blocks.<layer>.hook_mlp_out', sae_layer_template='layers.<layer>.mlp')
2025-03-18 03:26:52 [MainThread] [INFO] Configured Model Hook Points:
2025-03-18 03:26:52 [MainThread] [INFO] ['blocks.0.hook_mlp_out', 'blocks.1.hook_mlp_out', 'blocks.2.hook_mlp_out', 'blocks.3.hook_mlp_out', 'blocks.4.hook_mlp_out', 'blocks.5.hook_mlp_out', 'blocks.6.hook_mlp_out', 'blocks.7.hook_mlp_out', 'blocks.8.hook_mlp_out', 'blocks.9.hook_mlp_out', 'blocks.10.hook_mlp_out', 'blocks.11.hook_mlp_out', 'blocks.12.hook_mlp_out', 'blocks.13.hook_mlp_out', 'blocks.14.hook_mlp_out', 'blocks.15.hook_mlp_out', 'blocks.16.hook_mlp_out', 'blocks.17.hook_mlp_out', 'blocks.18.hook_mlp_out', 'blocks.19.hook_mlp_out', 'blocks.20.hook_mlp_out', 'blocks.21.hook_mlp_out', 'blocks.22.hook_mlp_out', 'blocks.23.hook_mlp_out']
2025-03-18 03:26:52 [MainThread] [INFO] Configured SAEs:
2025-03-18 03:26:52 [MainThread] [INFO] ['layers.0.mlp', 'layers.1.mlp', 'layers.2.mlp', 'layers.3.mlp', 'layers.4.mlp', 'layers.5.mlp', 'layers.6.mlp', 'layers.7.mlp', 'layers.8.mlp', 'layers.9.mlp', 'layers.10.mlp', 'layers.11.mlp', 'layers.12.mlp', 'layers.13.mlp', 'layers.14.mlp', 'layers.15.mlp', 'layers.16.mlp', 'layers.17.mlp', 'layers.18.mlp', 'layers.19.mlp', 'layers.20.mlp', 'layers.21.mlp', 'layers.22.mlp', 'layers.23.mlp']
2025-03-18 03:26:52 [MainThread] [INFO] Loading Dataset...
2025-03-18 03:26:52 [MainThread] [INFO] Loading Model...
2025-03-18 03:27:07 [ActivationConsumer] [INFO] Running consumer on cuda:1
Loaded pretrained model EleutherAI/pythia-410m into HookedTransformer
Moving model to device:  cuda:0
2025-03-18 03:28:07 [MainThread] [INFO] Loading SAE...
Loading SAEs
Fetching 49 files:   0%|          | 0/49 [00:00<?, ?it/s]Fetching 49 files: 100%|██████████| 49/49 [00:00<00:00, 37689.51it/s]
2025-03-18 03:28:08 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:28:08 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:28:08 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:28:08 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:28:08 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:28:09 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:28:09 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:28:09 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:28:09 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:28:09 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:28:10 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:28:10 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:28:10 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:28:10 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:28:10 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:28:11 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:28:11 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:28:11 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:28:11 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:28:12 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:28:12 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:28:12 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:28:12 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:28:12 [MainThread] [WARNING] Dropping extra args {'signed': False}
Finished Loading SAEs
2025-03-18 03:28:12 [MainThread] [INFO] Starting Inference...
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
TOKENIZERS_PARALLELISM=(true | false)
2025-03-18 03:28:13 [MainThread] [INFO] Processing batch 1/66...
2025-03-18 03:28:24 [MainThread] [INFO] Processing batch 2/66...
2025-03-18 03:28:35 [MainThread] [INFO] Processing batch 3/66...
2025-03-18 03:28:44 [MainThread] [INFO] Processing batch 4/66...
2025-03-18 03:28:53 [MainThread] [INFO] Processing batch 5/66...
2025-03-18 03:29:03 [MainThread] [INFO] Processing batch 6/66...
2025-03-18 03:29:13 [MainThread] [INFO] Processing batch 7/66...
2025-03-18 03:29:23 [MainThread] [INFO] Processing batch 8/66...
2025-03-18 03:29:32 [MainThread] [INFO] Enqueuing activations for shard 1...
2025-03-18 03:29:32 [MainThread] [INFO] Processing batch 9/66...
2025-03-18 03:29:39 [ActivationConsumer] [INFO] Consumer successfully processed shard 1
2025-03-18 03:29:42 [MainThread] [INFO] Processing batch 10/66...
2025-03-18 03:29:51 [MainThread] [INFO] Processing batch 11/66...
2025-03-18 03:30:00 [MainThread] [INFO] Processing batch 12/66...
2025-03-18 03:30:08 [MainThread] [INFO] Processing batch 13/66...
2025-03-18 03:30:17 [MainThread] [INFO] Processing batch 14/66...
2025-03-18 03:30:26 [MainThread] [INFO] Processing batch 15/66...
2025-03-18 03:30:35 [MainThread] [INFO] Processing batch 16/66...
2025-03-18 03:30:44 [MainThread] [INFO] Enqueuing activations for shard 2...
2025-03-18 03:30:44 [MainThread] [INFO] Processing batch 17/66...
2025-03-18 03:30:49 [ActivationConsumer] [INFO] Consumer successfully processed shard 2
2025-03-18 03:30:54 [MainThread] [INFO] Processing batch 18/66...
2025-03-18 03:31:02 [MainThread] [INFO] Processing batch 19/66...
2025-03-18 03:31:11 [MainThread] [INFO] Processing batch 20/66...
2025-03-18 03:31:20 [MainThread] [INFO] Processing batch 21/66...
2025-03-18 03:31:29 [MainThread] [INFO] Processing batch 22/66...
2025-03-18 03:31:38 [MainThread] [INFO] Processing batch 23/66...
2025-03-18 03:31:47 [MainThread] [INFO] Processing batch 24/66...
2025-03-18 03:31:55 [MainThread] [INFO] Enqueuing activations for shard 3...
2025-03-18 03:31:55 [MainThread] [INFO] Processing batch 25/66...
2025-03-18 03:32:03 [ActivationConsumer] [INFO] Consumer successfully processed shard 3
2025-03-18 03:32:05 [MainThread] [INFO] Processing batch 26/66...
2025-03-18 03:32:14 [MainThread] [INFO] Processing batch 27/66...
2025-03-18 03:32:23 [MainThread] [INFO] Processing batch 28/66...
2025-03-18 03:32:32 [MainThread] [INFO] Processing batch 29/66...
2025-03-18 03:32:41 [MainThread] [INFO] Processing batch 30/66...
2025-03-18 03:32:51 [MainThread] [INFO] Processing batch 31/66...
2025-03-18 03:33:00 [MainThread] [INFO] Processing batch 32/66...
2025-03-18 03:33:09 [MainThread] [INFO] Enqueuing activations for shard 4...
2025-03-18 03:33:09 [MainThread] [INFO] Processing batch 33/66...
2025-03-18 03:33:19 [ActivationConsumer] [INFO] Consumer successfully processed shard 4
2025-03-18 03:33:20 [MainThread] [INFO] Processing batch 34/66...
2025-03-18 03:33:29 [MainThread] [INFO] Processing batch 35/66...
2025-03-18 03:33:38 [MainThread] [INFO] Processing batch 36/66...
2025-03-18 03:33:48 [MainThread] [INFO] Processing batch 37/66...
2025-03-18 03:33:57 [MainThread] [INFO] Processing batch 38/66...
2025-03-18 03:34:06 [MainThread] [INFO] Processing batch 39/66...
2025-03-18 03:34:15 [MainThread] [INFO] Processing batch 40/66...
2025-03-18 03:34:24 [MainThread] [INFO] Enqueuing activations for shard 5...
2025-03-18 03:34:24 [MainThread] [INFO] Processing batch 41/66...
2025-03-18 03:34:29 [ActivationConsumer] [INFO] Consumer successfully processed shard 5
2025-03-18 03:34:33 [MainThread] [INFO] Processing batch 42/66...
2025-03-18 03:34:42 [MainThread] [INFO] Processing batch 43/66...
2025-03-18 03:34:52 [MainThread] [INFO] Processing batch 44/66...
2025-03-18 03:35:01 [MainThread] [INFO] Processing batch 45/66...
2025-03-18 03:35:09 [MainThread] [INFO] Processing batch 46/66...
2025-03-18 03:35:19 [MainThread] [INFO] Processing batch 47/66...
2025-03-18 03:35:28 [MainThread] [INFO] Processing batch 48/66...
2025-03-18 03:35:37 [MainThread] [INFO] Enqueuing activations for shard 6...
2025-03-18 03:35:37 [MainThread] [INFO] Processing batch 49/66...
2025-03-18 03:35:42 [ActivationConsumer] [INFO] Consumer successfully processed shard 6
2025-03-18 03:35:46 [MainThread] [INFO] Processing batch 50/66...
2025-03-18 03:35:55 [MainThread] [INFO] Processing batch 51/66...
2025-03-18 03:36:04 [MainThread] [INFO] Processing batch 52/66...
2025-03-18 03:36:13 [MainThread] [INFO] Processing batch 53/66...
2025-03-18 03:36:22 [MainThread] [INFO] Processing batch 54/66...
2025-03-18 03:36:31 [MainThread] [INFO] Processing batch 55/66...
2025-03-18 03:36:40 [MainThread] [INFO] Processing batch 56/66...
2025-03-18 03:36:50 [MainThread] [INFO] Enqueuing activations for shard 7...
2025-03-18 03:36:50 [MainThread] [INFO] Processing batch 57/66...
2025-03-18 03:36:54 [ActivationConsumer] [INFO] Consumer successfully processed shard 7
2025-03-18 03:36:59 [MainThread] [INFO] Processing batch 58/66...
2025-03-18 03:37:08 [MainThread] [INFO] Processing batch 59/66...
2025-03-18 03:37:17 [MainThread] [INFO] Processing batch 60/66...
2025-03-18 03:37:26 [MainThread] [INFO] Processing batch 61/66...
2025-03-18 03:37:35 [MainThread] [INFO] Processing batch 62/66...
2025-03-18 03:37:44 [MainThread] [INFO] Processing batch 63/66...
2025-03-18 03:37:54 [MainThread] [INFO] Processing batch 64/66...
2025-03-18 03:38:03 [MainThread] [INFO] Enqueuing activations for shard 8...
2025-03-18 03:38:03 [MainThread] [INFO] Processing batch 65/66...
2025-03-18 03:38:08 [ActivationConsumer] [INFO] Consumer successfully processed shard 8
2025-03-18 03:38:12 [MainThread] [INFO] Processing batch 66/66...
2025-03-18 03:38:19 [MainThread] [INFO] Enqueuing activations for shard 9...
2025-03-18 03:38:20 [ActivationConsumer] [INFO] Consumer successfully processed shard 9
2025-03-18 03:38:20 [ActivationConsumer] [INFO] Got sentinel for dataset 1. Finishing up.
2025-03-18 03:38:20 [ActivationConsumer] [INFO] Aggregating traditional metrics for 1
2025-03-18 03:38:20 [ActivationConsumer] [INFO] Received 9 binary probes for dataset 1.
2025-03-18 03:38:20 [ActivationConsumer] [INFO] Probes Received for dataset 1: ['data_subset_is_wikipedia', 'data_subset_is_pubmed_abstracts', 'data_subset_is_stack_exchange', 'data_subset_is_github', 'data_subset_is_arxiv', 'data_subset_is_uspto', 'data_subset_is_freelaw', 'data_subset_is_hackernews', 'data_subset_is_enron']
Exception in thread ActivationConsumer:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.11/threading.py", line 1045, in _bootstrap_inner
    self.run()
  File "/opt/conda/lib/python3.11/threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
  File "/home/mltrain/delta-selectivity-saes/main.py", line 219, in activation_consumer_thread
    sae_acts = torch.cat(sae_acts, dim=0).float()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 44.25 GiB. GPU 1 has a total capacity of 79.14 GiB of which 13.39 GiB is free. Process 2051218 has 65.74 GiB memory in use. Of the allocated memory 64.32 GiB is allocated by PyTorch, and 960.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-03-18 03:38:21 [MainThread] [INFO] Dataset 1 is fully processed.

2025-03-18 03:38:21 [MainThread] [INFO] Starting dataset 4...
2025-03-18 03:38:21 [ActivationConsumer] [INFO] Running consumer on cuda:1
2025-03-18 03:38:21 [MainThread] [INFO] Validating Arguments...
2025-03-18 03:38:21 [MainThread] [INFO] Computing activations with the following arguments:
2025-03-18 03:38:21 [MainThread] [INFO] Namespace(model_name='EleutherAI/pythia-410m', sae_name='EleutherAI/sae-pythia-410m-65k', dataset_idx=4, start_index=0, n_samples=None, device='cuda:0', batch_size=128, layers='0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23', output_size=1024, output_directory='results_410m', num_workers=2, model_hook_template='blocks.<layer>.hook_mlp_out', sae_layer_template='layers.<layer>.mlp')
2025-03-18 03:38:21 [MainThread] [INFO] Configured Model Hook Points:
2025-03-18 03:38:21 [MainThread] [INFO] ['blocks.0.hook_mlp_out', 'blocks.1.hook_mlp_out', 'blocks.2.hook_mlp_out', 'blocks.3.hook_mlp_out', 'blocks.4.hook_mlp_out', 'blocks.5.hook_mlp_out', 'blocks.6.hook_mlp_out', 'blocks.7.hook_mlp_out', 'blocks.8.hook_mlp_out', 'blocks.9.hook_mlp_out', 'blocks.10.hook_mlp_out', 'blocks.11.hook_mlp_out', 'blocks.12.hook_mlp_out', 'blocks.13.hook_mlp_out', 'blocks.14.hook_mlp_out', 'blocks.15.hook_mlp_out', 'blocks.16.hook_mlp_out', 'blocks.17.hook_mlp_out', 'blocks.18.hook_mlp_out', 'blocks.19.hook_mlp_out', 'blocks.20.hook_mlp_out', 'blocks.21.hook_mlp_out', 'blocks.22.hook_mlp_out', 'blocks.23.hook_mlp_out']
2025-03-18 03:38:21 [MainThread] [INFO] Configured SAEs:
2025-03-18 03:38:21 [MainThread] [INFO] ['layers.0.mlp', 'layers.1.mlp', 'layers.2.mlp', 'layers.3.mlp', 'layers.4.mlp', 'layers.5.mlp', 'layers.6.mlp', 'layers.7.mlp', 'layers.8.mlp', 'layers.9.mlp', 'layers.10.mlp', 'layers.11.mlp', 'layers.12.mlp', 'layers.13.mlp', 'layers.14.mlp', 'layers.15.mlp', 'layers.16.mlp', 'layers.17.mlp', 'layers.18.mlp', 'layers.19.mlp', 'layers.20.mlp', 'layers.21.mlp', 'layers.22.mlp', 'layers.23.mlp']
2025-03-18 03:38:21 [MainThread] [INFO] Loading Dataset...
2025-03-18 03:38:21 [MainThread] [INFO] Loading Model...
Loaded pretrained model EleutherAI/pythia-410m into HookedTransformer
Moving model to device:  cuda:0
2025-03-18 03:39:29 [MainThread] [INFO] Loading SAE...
Loading SAEs
Fetching 49 files:   0%|          | 0/49 [00:00<?, ?it/s]Fetching 49 files: 100%|██████████| 49/49 [00:00<00:00, 7569.27it/s]
2025-03-18 03:39:29 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:39:29 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:39:29 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:39:29 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:39:30 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:39:30 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:39:30 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:39:30 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:39:30 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:39:31 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:39:31 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:39:31 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:39:31 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:39:31 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:39:32 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:39:32 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:39:32 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:39:32 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:39:32 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:39:32 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:39:33 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:39:33 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:39:33 [MainThread] [WARNING] Dropping extra args {'signed': False}
2025-03-18 03:39:33 [MainThread] [WARNING] Dropping extra args {'signed': False}
Finished Loading SAEs
2025-03-18 03:39:33 [MainThread] [INFO] Starting Inference...
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-03-18 03:39:34 [MainThread] [INFO] Processing batch 1/220...
2025-03-18 03:39:43 [MainThread] [INFO] Processing batch 2/220...
2025-03-18 03:39:53 [MainThread] [INFO] Processing batch 3/220...
2025-03-18 03:40:02 [MainThread] [INFO] Processing batch 4/220...
2025-03-18 03:40:12 [MainThread] [INFO] Processing batch 5/220...
2025-03-18 03:40:21 [MainThread] [INFO] Processing batch 6/220...
2025-03-18 03:40:30 [MainThread] [INFO] Processing batch 7/220...
2025-03-18 03:40:40 [MainThread] [INFO] Processing batch 8/220...
2025-03-18 03:40:49 [MainThread] [INFO] Enqueuing activations for shard 1...
2025-03-18 03:40:49 [MainThread] [INFO] Processing batch 9/220...
2025-03-18 03:40:53 [ActivationConsumer] [INFO] Consumer successfully processed shard 1
2025-03-18 03:40:58 [MainThread] [INFO] Processing batch 10/220...
2025-03-18 03:41:08 [MainThread] [INFO] Processing batch 11/220...
2025-03-18 03:41:18 [MainThread] [INFO] Processing batch 12/220...
2025-03-18 03:41:27 [MainThread] [INFO] Processing batch 13/220...
2025-03-18 03:41:40 [MainThread] [INFO] Processing batch 14/220...
2025-03-18 03:41:51 [MainThread] [INFO] Processing batch 15/220...
2025-03-18 03:42:00 [MainThread] [INFO] Processing batch 16/220...
2025-03-18 03:42:09 [MainThread] [INFO] Enqueuing activations for shard 2...
2025-03-18 03:42:09 [MainThread] [INFO] Processing batch 17/220...
2025-03-18 03:42:13 [ActivationConsumer] [INFO] Consumer successfully processed shard 2
2025-03-18 03:42:18 [MainThread] [INFO] Processing batch 18/220...
2025-03-18 03:42:27 [MainThread] [INFO] Processing batch 19/220...
2025-03-18 03:42:35 [MainThread] [INFO] Processing batch 20/220...
2025-03-18 03:42:44 [MainThread] [INFO] Processing batch 21/220...
2025-03-18 03:42:53 [MainThread] [INFO] Processing batch 22/220...
2025-03-18 03:43:02 [MainThread] [INFO] Processing batch 23/220...
2025-03-18 03:43:11 [MainThread] [INFO] Processing batch 24/220...
2025-03-18 03:43:20 [MainThread] [INFO] Enqueuing activations for shard 3...
2025-03-18 03:43:20 [MainThread] [INFO] Processing batch 25/220...
2025-03-18 03:43:24 [ActivationConsumer] [INFO] Consumer successfully processed shard 3
2025-03-18 03:43:29 [MainThread] [INFO] Processing batch 26/220...
2025-03-18 03:43:38 [MainThread] [INFO] Processing batch 27/220...
2025-03-18 03:43:46 [MainThread] [INFO] Processing batch 28/220...
2025-03-18 03:43:55 [MainThread] [INFO] Processing batch 29/220...
2025-03-18 03:44:04 [MainThread] [INFO] Processing batch 30/220...
2025-03-18 03:44:13 [MainThread] [INFO] Processing batch 31/220...
2025-03-18 03:44:22 [MainThread] [INFO] Processing batch 32/220...
2025-03-18 03:44:31 [MainThread] [INFO] Enqueuing activations for shard 4...
2025-03-18 03:44:31 [MainThread] [INFO] Processing batch 33/220...
2025-03-18 03:44:36 [ActivationConsumer] [INFO] Consumer successfully processed shard 4
2025-03-18 03:44:41 [MainThread] [INFO] Processing batch 34/220...
2025-03-18 03:44:50 [MainThread] [INFO] Processing batch 35/220...
2025-03-18 03:44:59 [MainThread] [INFO] Processing batch 36/220...
2025-03-18 03:45:08 [MainThread] [INFO] Processing batch 37/220...
2025-03-18 03:45:17 [MainThread] [INFO] Processing batch 38/220...
2025-03-18 03:45:26 [MainThread] [INFO] Processing batch 39/220...
2025-03-18 03:45:35 [MainThread] [INFO] Processing batch 40/220...
2025-03-18 03:45:44 [MainThread] [INFO] Enqueuing activations for shard 5...
2025-03-18 03:45:44 [MainThread] [INFO] Processing batch 41/220...
2025-03-18 03:45:49 [ActivationConsumer] [INFO] Consumer successfully processed shard 5
2025-03-18 03:45:54 [MainThread] [INFO] Processing batch 42/220...
2025-03-18 03:46:02 [MainThread] [INFO] Processing batch 43/220...
2025-03-18 03:46:11 [MainThread] [INFO] Processing batch 44/220...
2025-03-18 03:46:21 [MainThread] [INFO] Processing batch 45/220...
2025-03-18 03:46:30 [MainThread] [INFO] Processing batch 46/220...
2025-03-18 03:46:39 [MainThread] [INFO] Processing batch 47/220...
2025-03-18 03:46:48 [MainThread] [INFO] Processing batch 48/220...
